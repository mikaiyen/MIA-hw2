{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Homework 2 : 單光子電腦斷層掃描的多類別分類\n","在這份作業中，請各位將 TODO 填寫好。\n","\n","1. 調整適當的參數。\n","2. 將 validation 空白處填起來讓程式能夠運作\n","3. 寫出當 mode = valid、test 的 getitem()。\n","4. split the training dataset。\n","5. 調整適當的 optimizer、scheduler，雖然不一定會比較好，但可以嘗試看看。\n","6. 畫出 train 跟 valid 的 Misclassification Rate 圖。\n","7. 用相似的手法建立 Resnet, VIT model 架構。\n","8. 在 testing 裡填空格。\n","9. 填寫 test_dataset、test_loader、model 三個空格。\n","10. 挑選你認為最好的 model 並將預測結果輸出在 submission.csv。"]},{"cell_type":"markdown","metadata":{},"source":["kaggle rule:\n","1. 不得使用兩隻以上的帳號繳交 submission檔案 (可參加但不可丟答案)\n","2. team的名稱記得一定要改成學號"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005463,"end_time":"2023-10-17T12:30:21.070608","exception":false,"start_time":"2023-10-17T12:30:21.065145","status":"completed"},"tags":[]},"source":["## Import Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:00.103031Z","iopub.status.busy":"2024-09-29T18:01:00.102618Z","iopub.status.idle":"2024-09-29T18:01:12.925140Z","shell.execute_reply":"2024-09-29T18:01:12.924039Z","shell.execute_reply.started":"2024-09-29T18:01:00.102985Z"},"papermill":{"duration":10.073221,"end_time":"2023-10-17T12:30:31.149011","exception":false,"start_time":"2023-10-17T12:30:21.075790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# torchsummary 可以讓模型視覺化，以及匯出模型每層的詳細數量和每層的比例。\n","# !pip install torchsummary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:23.564183Z","iopub.status.busy":"2024-09-29T18:01:23.562935Z","iopub.status.idle":"2024-09-29T18:01:23.570548Z","shell.execute_reply":"2024-09-29T18:01:23.569585Z","shell.execute_reply.started":"2024-09-29T18:01:23.564139Z"},"papermill":{"duration":14.261454,"end_time":"2023-10-17T12:30:45.416063","exception":false,"start_time":"2023-10-17T12:30:31.154609","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pydicom\n","import pandas as pd\n","import numpy as np\n","import os\n","import random\n","\n","import pydicom\n","import matplotlib.pyplot as plt\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, Subset, DataLoader\n","from torchvision.transforms import v2\n","import torchvision.models as models # VGG16, ResNet50\n","from torchsummary import summary # summary for models\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","print(torch.__version__)\n","print(torch.version.cuda)\n","print(torch.backends.cudnn.version())\n","print(torch.cuda.is_available())\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category = FutureWarning)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00529,"end_time":"2023-10-17T12:30:45.427720","exception":false,"start_time":"2023-10-17T12:30:45.422430","status":"completed"},"tags":[]},"source":["## Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-29T18:01:26.005487Z","iopub.status.busy":"2024-09-29T18:01:26.004622Z","iopub.status.idle":"2024-09-29T18:01:26.045403Z","shell.execute_reply":"2024-09-29T18:01:26.044458Z","shell.execute_reply.started":"2024-09-29T18:01:26.005444Z"},"papermill":{"duration":0.113167,"end_time":"2023-10-17T12:30:45.546313","exception":false,"start_time":"2023-10-17T12:30:45.433146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# TODO_1: 調整適當的參數(除了 num_classes，你可以任意調整以下的超參數)\n","\n","class config:\n","    \n","    root = \"./hwk02_data\" #\"/kaggle/input/2024dl\"\n","    batch_size = 16\n","    lr = 1e-4\n","    epochs = 150\n","    weight_decay = 1e-3\n","    seed = 42\n","    \n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    num_classes = 3\n","    \n","print('device:', config.device)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005373,"end_time":"2023-10-17T12:30:45.557207","exception":false,"start_time":"2023-10-17T12:30:45.551834","status":"completed"},"tags":[]},"source":["## Input Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:28.637378Z","iopub.status.busy":"2024-09-29T18:01:28.636992Z","iopub.status.idle":"2024-09-29T18:01:28.689768Z","shell.execute_reply":"2024-09-29T18:01:28.688724Z","shell.execute_reply.started":"2024-09-29T18:01:28.637342Z"},"papermill":{"duration":0.037164,"end_time":"2023-10-17T12:30:45.599600","exception":false,"start_time":"2023-10-17T12:30:45.562436","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(os.path.join(config.root, 'train.csv'))\n","test_data = pd.read_csv(os.path.join(config.root, 'test.csv'))\n","\n","print(f'Number of training samples: {train_data.shape[0]}')\n","print(f'Number of testing samples: {test_data.shape[0]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:30.933781Z","iopub.status.busy":"2024-09-29T18:01:30.932922Z","iopub.status.idle":"2024-09-29T18:01:30.954855Z","shell.execute_reply":"2024-09-29T18:01:30.953782Z","shell.execute_reply.started":"2024-09-29T18:01:30.933728Z"},"papermill":{"duration":0.028448,"end_time":"2023-10-17T12:30:45.633795","exception":false,"start_time":"2023-10-17T12:30:45.605347","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_data['Stage'].value_counts().sort_index()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:39.943295Z","iopub.status.busy":"2024-09-29T18:01:39.942500Z","iopub.status.idle":"2024-09-29T18:01:39.962039Z","shell.execute_reply":"2024-09-29T18:01:39.960888Z","shell.execute_reply.started":"2024-09-29T18:01:39.943252Z"},"papermill":{"duration":0.02058,"end_time":"2023-10-17T12:30:45.671558","exception":false,"start_time":"2023-10-17T12:30:45.650978","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def seed_everything(seed):\n","    # Set Python random seed\n","    random.seed(seed)\n","    \n","    # Set NumPy random seed\n","    np.random.seed(seed)\n","    \n","    # Set PyTorch random seed for CPU and GPU\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    \n","    # Set PyTorch deterministic operations for cudnn backend\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def evaluator(preds, gts):\n","    preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n","    gts = gts.cpu().numpy() if isinstance(gts, torch.Tensor) else gts\n","    acc = accuracy_score(preds, gts)\n","    f1 = f1_score(preds, gts, average = \"macro\")\n","    misclassification_rate = 1 - acc\n","    \n","    return acc, f1, misclassification_rate\n","\n","def train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n","    # 作用是啟用 batch normalization 和 dropout。\n","    # 保證 BN 層能夠用到每個 batch 資料的平均值和變異數。對於 Dropout 是隨機取一部分網路連線來訓練更新參數。\n","    model.train() \n","    \n","    train_loss = .0\n","    predictions, ground_truths = [], []\n","    \n","    for images, ages, genders, labels in train_loader:\n","        images = images.to(device = device, dtype = torch.float)\n","        ages = ages.to(device = device, dtype = torch.float)\n","        genders = genders.to(device = device, dtype = torch.float)\n","        labels = labels.to(device = device, dtype = torch.long)\n","\n","        optimizer.zero_grad()\n","        logits = model(images, ages, genders)\n","        \n","        # Pytorch 中的分類損失函數（如 CrossEntropyLoss）期望 label 為 0 開始的整數。\n","        labels = torch.sub(labels, 1) # labels 1, 2, 3 -> 0, 1, 2\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step() #switch place\n","\n","        train_loss += loss.item()\n","        preds = torch.argmax(logits, dim = 1)\n","\n","        predictions.append(preds)\n","        ground_truths.append(labels)\n","    # scheduler.step()\n","\n","    train_loss /= len(train_loader)\n","\n","    predictions = torch.cat(predictions)\n","    ground_truths = torch.cat(ground_truths)\n","    train_acc, train_f1, train_misclass = evaluator(predictions, ground_truths)\n","\n","    return train_loss, 100*train_acc, 100*train_f1, 100*train_misclass\n","\n","\n","def validation(model, valid_loader, criterion, device):\n","    # 確保 BN 層能夠用全部訓練資料的平均值和變異數，即驗證過程中要保證 BN 層的平均值和變異數不變。對於 Dropout 是利用了所有網路連接，即不進行隨機捨棄神經元。\n","    # pytorch 會自動把 BN 和 DropOut 固定住，不會取平均，而是用訓練好的數值。\n","    model.eval()\n","    valid_loss = .0\n","    predictions, ground_truths = [], []\n","\n","    # TODO_2: 請將空白處填起來讓程式能夠運作。\n","\n","    # 這邊禁用 PyTorch 梯度的自動計算，因為在 validation 階段我們不需要更新 model 的權重，因此不需要進行反向傳播(backpropagation)和梯度計算。\n","    with torch.no_grad():\n","        for images, ages, genders, labels in valid_loader:\n","            # Move data to the device (GPU or CPU)\n","            images = images.to(device=device, dtype=torch.float)\n","            ages = ages.to(device=device, dtype=torch.float)\n","            genders = genders.to(device=device, dtype=torch.float)\n","            labels = labels.to(device=device, dtype=torch.long)\n","\n","            # Forward pass: compute logits\n","            logits = model(images, ages, genders)\n","            \n","            # Adjust labels: converting from [1,2,3] to [0,1,2] as expected by CrossEntropyLoss\n","            labels = torch.sub(labels, 1)\n","            \n","            # Compute loss\n","            loss = criterion(logits, labels)\n","\n","            # Accumulate validation loss\n","            valid_loss += loss.item()\n","\n","            # Get predictions: select the index with the highest logit\n","            preds = torch.argmax(logits, dim=1)\n","\n","            # Append predictions and ground truths for evaluation\n","            predictions.append(preds)\n","            ground_truths.append(labels)\n","\n","        # Average validation loss over the entire dataset\n","        valid_loss /= len(valid_loader)\n","\n","        # Concatenate all predictions and ground truths from different batches\n","        predictions = torch.cat(predictions)\n","        ground_truths = torch.cat(ground_truths)\n","\n","        # Calculate validation accuracy, F1 score, and misclassification rate\n","        valid_acc, valid_f1, valid_misclass = evaluator(predictions, ground_truths)\n","        \n","    return valid_loss, 100*valid_acc, 100*valid_f1, 100*valid_misclass\n","\n","\n","def printTrainresult(history, eps):\n","    train_loss=history[\"train\"][\"loss\"][eps]\n","    train_acc=history[\"train\"][\"acc\"][eps]\n","    train_f1=history[\"train\"][\"f1\"][eps]\n","    train_misclass=history[\"train\"][\"misclass\"][eps]\n","    valid_loss=history[\"valid\"][\"loss\"][eps]\n","    valid_acc=history[\"valid\"][\"acc\"][eps]\n","    valid_f1=history[\"valid\"][\"f1\"][eps]\n","    valid_misclass=history[\"valid\"][\"misclass\"][eps]\n","    \n","    # Plot loss curves\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(range(config.epochs), history[\"train\"][\"loss\"], label='Training Loss')\n","    plt.plot(range(config.epochs), history[\"valid\"][\"loss\"], label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.title('Training and Validation Loss Curves')\n","    plt.show()\n","\n","    # Plot accuracy curves\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(range(config.epochs), history[\"train\"][\"acc\"], label='Training Accuracy')\n","    plt.plot(range(config.epochs), history[\"valid\"][\"acc\"], label='Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.title('Training and Validation Accuracy Curves')\n","    plt.show()\n","\n","    # Plot F1 score curves\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(range(config.epochs), history[\"train\"][\"f1\"], label='Training F1 Score')\n","    plt.plot(range(config.epochs), history[\"valid\"][\"f1\"], label='Validation F1 Score')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('F1 Score')\n","    plt.legend()\n","    plt.title('Training and Validation F1 Score Curves')\n","    plt.show()\n","\n","    # Plot misclassification rate curves\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(range(config.epochs), history[\"train\"][\"misclass\"], label='Training Misclassification')\n","    plt.plot(range(config.epochs), history[\"valid\"][\"misclass\"], label='Validation Misclassification')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Misclassification Rate (%)')\n","    plt.legend()\n","    plt.title('Training and Validation Misclassification Rate')\n","    plt.show()\n","    \n","    print(\"BatchSize: \",config.batch_size,\" / LR: \",config.lr,\" / WeightDecay: \",config.weight_decay,\" / Seed: \",config.seed)\n","    print(f'Best result: Epoch{eps+1},\\\n","        \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Train F1: {train_f1:.2f}% |\\\n","        \\nValid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.2f}%, Valid F1: {valid_f1:.2f}%, Valid Misclass: {valid_misclass:.2f}%')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Transformation"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:45.016867Z","iopub.status.busy":"2024-09-29T18:01:45.016159Z","iopub.status.idle":"2024-09-29T18:01:45.023521Z","shell.execute_reply":"2024-09-29T18:01:45.022535Z","shell.execute_reply.started":"2024-09-29T18:01:45.016826Z"},"trusted":true},"outputs":[],"source":["class Normalization(object):\n","    \n","    def __call__(self, image): # 定義有image之後要進行的資料處理\n","        changed_image = (image - image.min())/(image.max() - image.min())\n","        return changed_image\n","\n","def build_transform(is_train):\n","    \"\"\"\n","    Create a data transformation pipeline for image preprocessing in deep learning tasks.\n","    \"\"\"\n","    t = []\n","    if is_train:\n","        # 若是包含 Random 系列的圖像增強，則只能加在train裡面\n","        t.append(v2.CenterCrop(size = (50, 50)))\n","        t.append(Normalization())\n","        return v2.Compose(t)\n","    \n","    t.append(v2.CenterCrop(size = (50, 50)))\n","    t.append(Normalization())\n","    return v2.Compose(t)\n","\n","def build_transform_ViT(is_train):\n","    \"\"\"\n","    Create a data transformation pipeline for image preprocessing in deep learning tasks.\n","    \"\"\"\n","    t = []\n","    if is_train:\n","        t.append(v2.Grayscale(num_output_channels=1))  # Convert to grayscale\n","        t.append(v2.CenterCrop(size=(56, 56)))\n","        t.append(Normalization())\n","        return v2.Compose(t)\n","    t.append(v2.Grayscale(num_output_channels=1))  # Convert to grayscale (1 channel)\n","    t.append(v2.CenterCrop(size=(56, 56)))      # Crop to 56x56\n","    t.append(Normalization())\n","    return v2.Compose(t)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005345,"end_time":"2023-10-17T12:30:45.682512","exception":false,"start_time":"2023-10-17T12:30:45.677167","status":"completed"},"tags":[]},"source":["## Defined Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:01:47.506343Z","iopub.status.busy":"2024-09-29T18:01:47.505425Z","iopub.status.idle":"2024-09-29T18:01:47.521147Z","shell.execute_reply":"2024-09-29T18:01:47.518493Z","shell.execute_reply.started":"2024-09-29T18:01:47.506276Z"},"trusted":true},"outputs":[],"source":["class ParkinsonsDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df, mode = None, transforms = None): # 將所有資料提出\n","        self.df = df\n","        self.mode = mode\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, x): # 找出指定的資料\n","        \n","        age = torch.tensor(self.df.iloc[x, 1]) # 年齡\n","        gender = torch.tensor(self.df.iloc[x, 2]) # 性別\n","        index = torch.tensor(self.df.iloc[x, 4]) # 起始張數\n","        \n","        # 影像前處理\n","        image = pydicom.dcmread(config.root + self.df.iloc[x, 3]).pixel_array\n","        image = torch.tensor(image.astype(np.float32))\n","        image = image[index-1:index+2, :, :]\n","        \n","        if self.mode == \"train\":\n","            label = torch.tensor(self.df.iloc[x, 5]) # 標籤\n","            if self.transforms: image = self.transforms(image)\n","\n","            return image, age, gender, label\n","        \n","        \n","        # TODO_3: 寫出當 mode = valid、test 的 getitem()\n","        elif self.mode == \"valid\":\n","            # Extract label for validation\n","            label = torch.tensor(self.df.iloc[x, 5], dtype=torch.long)  # Label for validation\n","            if self.transforms: image = self.transforms(image)\n","            return image, age, gender, label\n","\n","        elif self.mode == \"test\":\n","            # In test mode, there is no label to return\n","            if self.transforms: image = self.transforms(image)\n","            return image, age, gender"]},{"cell_type":"markdown","metadata":{},"source":["## Redefined Resnet\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:34:35.622378Z","iopub.status.busy":"2024-09-28T07:34:35.621797Z","iopub.status.idle":"2024-09-28T07:34:35.631790Z","shell.execute_reply":"2024-09-28T07:34:35.630491Z","shell.execute_reply.started":"2024-09-28T07:34:35.622289Z"},"trusted":true},"outputs":[],"source":["# TODO_7: 用跟 VGG 類似的方式建立 Resnet\n","\n","class ResNetplus(nn.Module):\n","    def __init__(self, num_classes, input_size=(3, 50, 50), features_grad=False):\n","        super().__init__()\n","\n","        # Load the pre-trained ResNet50 model\n","        resnet50 = models.resnet50(weights='IMAGENET1K_V1', progress=True)\n","\n","        # Replace the final fully connected layer with nn.Identity() to act as a placeholder\n","        # This lets us add our own classification layers later.\n","        resnet50.fc = nn.Identity()\n","\n","        # Freeze or unfreeze ResNet50 feature layers\n","        for param in resnet50.parameters():\n","            param.requires_grad = features_grad\n","        self.backend = resnet50\n","\n","        # Add the custom classifier that combines image features with age and gender\n","        # resnet50 outputs a 2048-dimensional feature vector, and we add age & gender (2 features)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2048 + 2, num_classes)  # 2048: ResNet50 feature vector size, 2: age & gender\n","        )\n","        self.softmax = nn.Softmax(dim=1) # 每一個row的總和都是1\n","\n","    def forward(self, x, age, gender):\n","        # Pass the input through the ResNet50 backbone\n","        features = self.backend(x)\n","\n","        # Concatenate the ResNet output with age and gender features\n","        combined_features = torch.cat([features, age.view(-1, 1), gender.view(-1, 1)], dim=1)  # Concatenate along the column\n","\n","        # Pass the combined features through the custom classifier\n","        outputs = self.classifier(combined_features)\n","        # if self.out_prob:\n","        #     outputs = self.softmax(outputs)\n","        return outputs    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def main():\n","    seed_everything(config.seed)\n","    \n","    # train dataframe\n","    train_data = pd.read_csv(os.path.join(config.root, 'train.csv'))\n","    \n","    \n","    # TODO_4: split the training dataset，通常是 8:2，但可以嘗試其他的分法，e.g. 7:3。\n","    train_dataset, val_dataset = train_test_split(train_data, train_size=0.8, test_size=0.2, random_state=config.seed)\n","\n","    train_dataset = ParkinsonsDataset(train_dataset, transforms = build_transform(True), mode = \"train\")\n","    val_dataset = ParkinsonsDataset(val_dataset, transforms = build_transform(False), mode = \"valid\")\n","    \n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True)\n","    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = config.batch_size, shuffle = False)\n","    \n","    # settings\n","    print(\"Initializing model...\")\n","    model = ResNetplus(num_classes = config.num_classes, features_grad = True)\n","    model.to(config.device)\n","    \n","    criterion = nn.CrossEntropyLoss().to(config.device)\n","    parameters = [p for p in model.parameters() if p.requires_grad] \n","    \n","    optimizer = torch.optim.Adam(parameters, lr = config.lr, weight_decay = config.weight_decay)\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","        optimizer = optimizer,\n","        epochs = config.epochs,\n","        steps_per_epoch = train_loader.__len__(),\n","        max_lr = config.lr,\n","        anneal_strategy = 'cos'\n","    )\n","\n","    # recordings\n","    best_val_loss = float(\"inf\")\n","    history = {\n","        \"train\": {\n","            \"loss\": [],\n","            \"acc\": [],\n","            \"f1\": [],\n","            \"misclass\": []\n","        },\n","        \"valid\": {\n","            \"loss\": [],\n","            \"acc\": [],\n","            \"f1\": [],\n","            \"misclass\": []\n","        },\n","    }\n","    besteps= 0\n","    \n","\n","    for epoch in range(config.epochs):\n","        train_loss, train_acc, train_f1, train_misclass = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n","        valid_loss, valid_acc, valid_f1, valid_misclass = validation(model, val_loader, criterion, config.device)\n","        \n","        # Log the loss and validation result\n","        history[\"train\"][\"loss\"].append(train_loss)\n","        history[\"train\"][\"acc\"].append(train_acc)\n","        history[\"train\"][\"f1\"].append(train_f1)\n","        history[\"train\"][\"misclass\"].append(train_misclass)\n","        history[\"valid\"][\"loss\"].append(valid_loss)\n","        history[\"valid\"][\"acc\"].append(valid_acc)\n","        history[\"valid\"][\"f1\"].append(valid_f1)\n","        history[\"valid\"][\"misclass\"].append(valid_misclass)\n","\n","        print(f'Epoch[{epoch+1}/{config.epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Train F1: {train_f1:.2f}% | Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.2f}%, Valid F1: {valid_f1:.2f}%, Valid Misclass: {valid_misclass:.2f}% | LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n","        \n","        if valid_loss < best_val_loss:\n","            save_file = {\n","                \"model\": model.state_dict(),\n","                \"optimizer\": optimizer.state_dict(),\n","                \"scheduler\": scheduler.state_dict(),\n","                \"epoch\": epoch,\n","                \"args\": config\n","            }\n","            best_val_loss = valid_loss\n","            torch.save(save_file, \"checkpointFiles/checkpointRes.pth\")\n","            besteps=epoch\n","\n","        best_ckpt = torch.load(\"checkpointFiles/checkpointRes.pth\", map_location = config.device, weights_only = False)\n","        model.load_state_dict(best_ckpt[\"model\"])\n","        \n","    printTrainresult(history,besteps)\n","\n","    \n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{},"source":["## testing"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:04:35.346534Z","iopub.status.busy":"2024-09-29T18:04:35.345810Z","iopub.status.idle":"2024-09-29T18:04:35.353330Z","shell.execute_reply":"2024-09-29T18:04:35.352456Z","shell.execute_reply.started":"2024-09-29T18:04:35.346486Z"},"trusted":true},"outputs":[],"source":["def testing(model, test_loader, device):\n","    model.eval()\n","    preds = []\n","    with torch.no_grad(): \n","        for image, age, gender in test_loader:\n","            image = image.to(device = device, dtype = torch.float)\n","            age = age.to(device)\n","            gender = gender.to(device)\n","            logits = model(image, age, gender)\n","            pred = torch.argmax(logits, dim = 1)\n","            preds.append(pred)\n","\n","    preds = torch.cat(preds)\n","    \n","    # TODO_8: 因為輸出的 preds為 0,1,2，所以請調整成 1,2,3。\n","    preds = preds + 1\n","    \n","    return preds\n","    \n","seed_everything(config.seed)\n","test_data = pd.read_csv(os.path.join(config.root, 'test.csv'))\n","\n","# TODO_9: 填寫 test_dataset、test_loader、model 四個空格，記得 test_loader 的 shuffle = False。\n","\n","# Creating the test dataset using the ParkinsonsDataset class\n","test_dataset1 = ParkinsonsDataset(test_data, mode=\"test\", transforms=build_transform(is_train=False))\n","# Creating the test dataset using the ParkinsonsDataset class\n","test_dataset2 = ParkinsonsDataset(test_data, mode=\"test\", transforms=build_transform_ViT(is_train=False))\n","\n","# DataLoader for the test dataset (shuffle is set to False)\n","test_loader1 = torch.utils.data.DataLoader(test_dataset1, batch_size=config.batch_size, shuffle=False)\n","test_loader2 = torch.utils.data.DataLoader(test_dataset2, batch_size=config.batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model2 = ResNetplus(num_classes=config.num_classes, features_grad=True)\n","\n","best_ckpt = torch.load(f\"checkpointFiles/checkpointRes.pth\", map_location=config.device)\n","model2.load_state_dict(best_ckpt[\"model\"])\n","\n","model2.to(config.device)\n","\n","\n","preds = testing(model2, test_loader1, config.device)\n","# Create a DataFrame with predictions\n","submission_df2 = pd.DataFrame()  # Start with an empty DataFrame\n","submission_df2['ID'] = test_data['ID']\n","\n","# Add the 'Stage' column with predictions\n","submission_df2['Stage'] = preds.cpu().numpy()  # Convert preds from GPU to CPU and then to NumPy\n","\n","# Specify the path for the submission file\n","submission_file_path2 = os.path.join(config.root, 'submissionRes.csv')  # Ensure this points to the desired directory\n","\n","# Save the DataFrame to a CSV file\n","submission_df2.to_csv(submission_file_path2, index=False, header=True)  # Save without index and with header\n","\n","print(f\"Predictions saved to {submission_file_path2}.\")  # Print confirmation message\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5663979,"sourceId":9461964,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"py38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"papermill":{"default_parameters":{},"duration":124.543825,"end_time":"2023-10-17T12:32:22.447419","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-17T12:30:17.903594","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
